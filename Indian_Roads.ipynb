{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This block of code is used to get the data of National Highways and their embeded links\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "html = urlopen('https://en.wikipedia.org/wiki/List_of_National_Highways_in_India_by_highway_number')\n",
    "bsObj = BeautifulSoup(html, 'lxml')\n",
    "A = []\n",
    "B = []\n",
    "C = []\n",
    "D = []\n",
    "E = []\n",
    "F = []\n",
    "G = []\n",
    "H = []\n",
    "for data in bsObj.body.find('table', {'class' : 'wikitable sortable'}).findAll('tr'):\n",
    "    cells = data.findAll('td')\n",
    "    if data.find('td') is None:\n",
    "        pass\n",
    "    else:\n",
    "        A.append('National Highway ' + cells[0].find(text = True) + ' (India)')\n",
    "        B.append(cells[1].find(text = True))\n",
    "        C.append(cells[2].find(text = True))\n",
    "        D.append(cells[3].find(text = True))\n",
    "        E.append(cells[4].find(text = True))\n",
    "        F.append('https://en.wikipedia.org' + cells[0].find('a').attrs['href'])\n",
    "        if cells[1].find('a') is None:\n",
    "            G.append('None')\n",
    "        else:\n",
    "            G.append(cells[1].find('a').attrs['href'])\n",
    "        #for url in data.findAll('a', href = re.compile('^(/wiki/National_Highway)')):\n",
    "            #A.append(url.attrs['title'])\n",
    "            #F.append(url.attrs['href'])\n",
    "        #for url in data.findAll('a', href = re.compile('^(/wiki/)(?!National)')):\n",
    "            #G.append(url.attrs['href'])\n",
    "            #H.append(url.text)\n",
    "\n",
    "#import pandas to convert list to data frame\n",
    "import pandas as pd\n",
    "df=pd.DataFrame(A,columns=['National Highways'])\n",
    "df['OSMRI'] = B #OSMRI : Open Street Map Relation Identifier\n",
    "df['States'] = C\n",
    "df['length'] = D\n",
    "df['routes'] = E\n",
    "df['National Highway URLS'] = F\n",
    "df['OSMRI_URL'] = G\n",
    "#print (df)\n",
    "df.to_csv('National_Highways.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This block of code is used to extract urls from http://badroadsinindia.com/ go to the every url and download \n",
    "the images of road maps of each state from http://www.mapsofindia.com/statename\n",
    "\"\"\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import requests\n",
    "html = urlopen('http://badroadsinindia.com/')\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "\n",
    "try:\n",
    "    def download_image(url,name):\n",
    "        res = requests.get(url)\n",
    "        #res.raise_for_status()\n",
    "        image = open(name,'wb')\n",
    "        for chunk in res.iter_content(100000):\n",
    "            image.write(chunk)\n",
    "        image.close()\n",
    "\n",
    "    A = []\n",
    "    name = []\n",
    "    states = []\n",
    "    first_urls = []\n",
    "    complete_urls = []\n",
    "    for data in soup.findAll('a', href = re.compile('^(http://www.mapsofindia.com)')):\n",
    "        A.append(data.attrs['href'])\n",
    "        states.append(data.text.lower().replace(' ','-'))\n",
    "    for link in A:\n",
    "        url_string = link.split('/')\n",
    "        needed_url = '/'.join(url_string[ : -1])\n",
    "        first_urls.append(needed_url)\n",
    "    for i in range(len(A)):\n",
    "        complete_urls.append(first_urls[i] + '/' + states[i] + '-road-map.jpg')\n",
    "    for i in range(len(complete_urls)):\n",
    "        name.append(str(states[i]).upper().replace('-',' ') + ' roads.jpg')\n",
    "        download_image(complete_urls[i], name[i])\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print (err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Code for Dandegous_Roads_In_India\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "#Using requests we can download html file of a web page\n",
    "\n",
    "req = requests.get('http://www.indiatimes.com/culture/travel/15-dangerous-roads-in-india-that-are-a-driverâ€™s-worst-nightmare-245762.html')\n",
    "req.raise_for_status()\n",
    "road_woes = open('India_times.html', 'wb')\n",
    "for chunk in req.iter_content(100000):\n",
    "    road_woes.write(chunk)\n",
    "road_woes.close()\n",
    "\n",
    "try:\n",
    "    html = open('/home/damodhar/MyPythonScripts/Assignment2/India_times.html')\n",
    "    soup = BeautifulSoup(html, 'lxml')\n",
    "    A = []\n",
    "    B = []\n",
    "    #C = []\n",
    "    name_of_road = []\n",
    "    \n",
    "    for data in (soup.find('div', {'class' : 'div-fixed'}).findAll('h3')):\n",
    "        A.append(data.text)\n",
    "        \n",
    "    for data in (soup.find('div', {'class' : 'div-fixed'}).findAll('p')):\n",
    "        if data.find('img', src = re.compile('^(http)')) is None:\n",
    "            if (data.find('iframe', src = re.compile('^(http)'))) is None:\n",
    "                pass\n",
    "            else:\n",
    "                B.append(data.find('iframe', src = re.compile('^(http)'))['src'])\n",
    "        else:\n",
    "            B.append(data.find('img', src = re.compile('^(http)'))['src'])\n",
    "    \n",
    "    #list index out of range(Urls are the mix of images and videos and the videos doesn't contain image credit)\n",
    "    #for data in (soup.find('div', {'class' : 'div-fixed'}).find('p').findAll('span', {'class' : 'source_link'})):\n",
    "        #C.append(data.text.replace('Image Credit: ', ''))\n",
    "        \n",
    "    for i in range(len(A)):\n",
    "        string = A[i].split(' ')\n",
    "        name_of_road.append(' '.join(string[1 : ]))\n",
    "        download_image(B[i], name_of_road[i] + '.jpg')\n",
    "    \n",
    "    def download_image(url, name):\n",
    "        req = requests.get(url)\n",
    "        req.raise_for_status()\n",
    "        image = open(name, 'wb')\n",
    "        for chunk in req.iter_content(100000):\n",
    "            image.write(chunk)\n",
    "        image.close()\n",
    "except requests.exceptions.HTTPError as err:\n",
    "    print (err)\n",
    "\n",
    "df=pd.DataFrame(name_of_road,columns=['Road Name'])\n",
    "df[\"Road's image Url\"] = B\n",
    "#df['Image Credit'] = C\n",
    "df.to_csv('Dangerous_Roads_In_India.csv',index=True,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "req = requests.get('http://www.badroadsinindia.com/')\n",
    "req.raise_for_status()\n",
    "road_woes = open('road_woes.html', 'wb')\n",
    "for chunk in req.iter_content(100000):\n",
    "    road_woes.write(chunk)\n",
    "road_woes.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "req = requests.get('https://en.wikipedia.org/wiki/List_of_National_Highways_in_India_by_highway_number')\n",
    "req.raise_for_status()\n",
    "nh_roads = open('nh_roads.html', 'wb')\n",
    "for chunk in req.iter_content(100000):\n",
    "    nh_roads.write(chunk)\n",
    "nh_roads.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
